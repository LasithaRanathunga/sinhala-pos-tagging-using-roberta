{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e252e51b",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e089373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pos_data(path):\n",
    "    dataset = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                # End of a sentence\n",
    "                if tokens:\n",
    "                    dataset.append({\"tokens\": tokens, \"tags\": tags})\n",
    "                    tokens = []\n",
    "                    tags = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    word, tag = parts\n",
    "                    tokens.append(word)\n",
    "                    tags.append(tag)\n",
    "        # Catch the last sentence if no newline at EOF\n",
    "        if tokens:\n",
    "            dataset.append({\"tokens\": tokens, \"tags\": tags})\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a3331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tokens': ['‡∂ä‡∑Å‡∑ä‡∂ª‡∑è‡∂∫‡∂Ω‡∑ä', '‡∂∏‡∑í‡∑É‡∂∫‡∑í‡∂Ω', '‡∂¥‡∑ä‡∂ª‡∑Ñ‡∑è‡∂ª', '‡∑Ä‡∂Ω‡∑í‡∂±‡∑ä', '‡∂¥‡∂Ω‡∑É‡∑ä‡∂≠‡∑ì‡∂±‡∑î‡∑Ä‡∑ù', '4', '‡∂ö‡∑ä', '‡∂∏‡∑í‡∂∫', '‡∂∫‡∂≠‡∑í', '.'], 'tags': ['NNP', 'NNJ', 'NNC', 'CM', 'NNP', 'NUM', 'RP', 'RRPCV', 'VFM', 'FS']}, {'tokens': ['‡∂ú‡∑è‡∑É‡∑è', '‡∂≠‡∑ì‡∂ª‡∂∫‡∑ö‡∂Ø‡∑ì', '.'], 'tags': ['NNP', 'NNP', 'FS']}]\n"
     ]
    }
   ],
   "source": [
    "print(load_pos_data(\"sinhala_pos.txt\")[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307ac143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "# all_data = load_pos_data(\"sinhala_pos.txt\")\n",
    "# random.shuffle(all_data)\n",
    "\n",
    "# # Optional: 80% train, 20% test split\n",
    "# split_idx = int(0.8 * len(all_data))\n",
    "# train_data = all_data[:split_idx]\n",
    "# test_data = all_data[split_idx:]\n",
    "\n",
    "# dataset = DatasetDict({\n",
    "#     \"train\": Dataset.from_list(train_data),\n",
    "#     \"test\": Dataset.from_list(test_data),\n",
    "# })\n",
    "\n",
    "data = load_pos_data(\"sinhala_pos.txt\")\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75e430",
   "metadata": {},
   "source": [
    "### tag2id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58584ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set(tag for example in data for tag in example[\"tags\"])\n",
    "\n",
    "tag2id = {tag: i for i, tag in enumerate(sorted(unique_tags))}\n",
    "label_list = list(tag2id.keys())\n",
    "\n",
    "id2tag = {i: tag for tag, i in tag2id.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac2906",
   "metadata": {},
   "source": [
    "### Tokenize and Align Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263ae3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9040/9040 [00:07<00:00, 1172.91 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2261/2261 [00:01<00:00, 1363.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"tokens\"], \n",
    "        is_split_into_words=True, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\",      # Pad to max length of the model or your max_length param\n",
    "        max_length=256,            # or any max_length you want (optional)\n",
    "        return_tensors=None        # don't convert to tensors here; Trainer does it later\n",
    "    )\n",
    "    \n",
    "    word_ids = tokenized.word_ids()\n",
    "    labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            labels.append(tag2id[example[\"tags\"][word_idx]])\n",
    "        else:\n",
    "            # Label only the first sub-token\n",
    "            labels.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db6892",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629a9d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    num_labels=len(tag2id),\n",
    "    id2label=id2tag,\n",
    "    label2id=tag2id,\n",
    "    local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ccb24e",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9231ff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_15088\\3450742309.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [565/565 1:21:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705700</td>\n",
       "      <td>0.343603</td>\n",
       "      <td>0.905514</td>\n",
       "      <td>0.904922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=565, training_loss=0.6697956051446695, metrics={'train_runtime': 4894.5893, 'train_samples_per_second': 1.847, 'train_steps_per_second': 0.115, 'total_flos': 1181488456581120.0, 'train_loss': 0.6697956051446695, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "# from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     preds = np.argmax(p.predictions, axis=2)\n",
    "#     labels = p.label_ids\n",
    "\n",
    "#     true_preds = [\n",
    "#         [id2tag[p] for (p, l) in zip(pred_seq, label_seq) if l != -100]\n",
    "#         for pred_seq, label_seq in zip(preds, labels)\n",
    "#     ]\n",
    "#     true_labels = [\n",
    "#         [id2tag[l] for (p, l) in zip(pred_seq, label_seq) if l != -100]\n",
    "#         for pred_seq, label_seq in zip(preds, labels)\n",
    "#     ]\n",
    "\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "#         \"report\": classification_report(true_labels, true_preds),\n",
    "#     }\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=2)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Convert IDs to tag names, skip padding (-100)\n",
    "\n",
    "    \n",
    "    true_preds = [\n",
    "        id2tag[p] for pred_seq, label_seq in zip(preds, labels)\n",
    "        for p, l in zip(pred_seq, label_seq) if l != -100\n",
    "    ]\n",
    "    true_labels = [\n",
    "        id2tag[l] for pred_seq, label_seq in zip(preds, labels)\n",
    "        for p, l in zip(pred_seq, label_seq) if l != -100\n",
    "    ]\n",
    "\n",
    "    # Optional: print detailed report to console (not return)\n",
    "    print(classification_report(true_labels, true_preds, digits=4))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds, average=\"weighted\"),\n",
    "        # Avoid printing report here in returned dict ‚Äî it's too long\n",
    "        # Use print manually if needed:\n",
    "        # print(classification_report(true_labels, true_preds))\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pos-xlm-r\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84beb556",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f613e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3436029255390167,\n",
       " 'eval_accuracy': 0.90551371868123,\n",
       " 'eval_f1': 0.9049217239183525,\n",
       " 'eval_runtime': 112.1416,\n",
       " 'eval_samples_per_second': 20.162,\n",
       " 'eval_steps_per_second': 1.266,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73480896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB       0.94      0.98      0.96       426\n",
      "         AUX       0.92      0.96      0.94       300\n",
      "          CC       0.97      0.96      0.96       687\n",
      "          CM       0.94      0.95      0.95       434\n",
      "         DET       0.96      0.96      0.96      1165\n",
      "         FRW       0.00      0.00      0.00         1\n",
      "          FS       1.00      1.00      1.00      2252\n",
      "         JCV       0.67      0.65      0.66       622\n",
      "          JJ       0.85      0.81      0.83      3557\n",
      "         NCV       0.72      0.80      0.76       927\n",
      "         NDT       0.00      0.00      0.00        14\n",
      "         NIP       0.97      0.96      0.97       857\n",
      "          NN       0.00      0.00      0.00         1\n",
      "         NNC       0.91      0.90      0.90     12213\n",
      "         NNJ       0.65      0.78      0.71      1296\n",
      "         NNP       0.93      0.92      0.93      5063\n",
      "         NNp       0.00      0.00      0.00         1\n",
      "         NUM       0.94      0.97      0.95      1166\n",
      "         NVB       0.59      0.61      0.60       174\n",
      "         NVF       0.00      0.00      0.00         1\n",
      "        POST       0.93      0.95      0.94      3628\n",
      "         PRP       0.97      0.94      0.96      1376\n",
      "        PUNC       0.99      1.00      1.00      1838\n",
      "         QBE       0.50      0.08      0.14        37\n",
      "         QUE       0.00      0.00      0.00        17\n",
      "          RB       0.78      0.77      0.77       496\n",
      "          RP       0.94      0.96      0.95      1275\n",
      "       RRPCV       0.83      0.86      0.85       844\n",
      "         UNK       0.00      0.00      0.00        55\n",
      "         URL       0.00      0.00      0.00         1\n",
      "         VFM       0.91      0.96      0.93      1346\n",
      "         VNF       0.92      0.91      0.91      2545\n",
      "         VNN       0.92      0.88      0.90      1417\n",
      "          VP       0.91      0.92      0.92      3498\n",
      "         VVF       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.91     49531\n",
      "   macro avg       0.64      0.64      0.64     49531\n",
      "weighted avg       0.91      0.91      0.90     49531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "preds = predictions_output.predictions.argmax(-1)\n",
    "labels = predictions_output.label_ids\n",
    "\n",
    "# Flatten predictions, ignoring -100\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for pred_seq, label_seq in zip(preds, labels):\n",
    "    for pred, label in zip(pred_seq, label_seq):\n",
    "        if label != -100:\n",
    "            true_labels.append(label)\n",
    "            predicted_labels.append(pred)\n",
    "\n",
    "# Dynamically detect used label IDs\n",
    "used_label_ids = sorted(set(true_labels + predicted_labels))\n",
    "\n",
    "# Match label IDs to tag names\n",
    "target_names = [id2tag[i] for i in used_label_ids]\n",
    "\n",
    "# Evaluate safely with matching label set\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    predicted_labels,\n",
    "    labels=used_label_ids,\n",
    "    target_names=target_names,\n",
    "    zero_division=0  # prevents warnings for unseen labels\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f32102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n",
      "üîç Evaluation Metrics from trainer.evaluate():\n",
      "eval_loss: 0.3436\n",
      "eval_accuracy: 0.9055\n",
      "eval_f1: 0.9049\n",
      "eval_runtime: 112.0800\n",
      "eval_samples_per_second: 20.1730\n",
      "eval_steps_per_second: 1.2670\n",
      "epoch: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB       0.94      0.98      0.96       426\n",
      "         AUX       0.92      0.96      0.94       300\n",
      "          CC       0.97      0.96      0.96       687\n",
      "          CM       0.94      0.95      0.95       434\n",
      "         DET       0.96      0.96      0.96      1165\n",
      "         FRW       0.00      0.00      0.00         1\n",
      "          FS       1.00      1.00      1.00      2252\n",
      "         JCV       0.67      0.65      0.66       622\n",
      "          JJ       0.85      0.81      0.83      3557\n",
      "         NCV       0.72      0.80      0.76       927\n",
      "         NDT       0.00      0.00      0.00        14\n",
      "         NIP       0.97      0.96      0.97       857\n",
      "          NN       0.00      0.00      0.00         1\n",
      "         NNC       0.91      0.90      0.90     12213\n",
      "         NNJ       0.65      0.78      0.71      1296\n",
      "         NNP       0.93      0.92      0.93      5063\n",
      "         NNp       0.00      0.00      0.00         1\n",
      "         NUM       0.94      0.97      0.95      1166\n",
      "         NVB       0.59      0.61      0.60       174\n",
      "         NVF       0.00      0.00      0.00         1\n",
      "        POST       0.93      0.95      0.94      3628\n",
      "         PRP       0.97      0.94      0.96      1376\n",
      "        PUNC       0.99      1.00      1.00      1838\n",
      "         QBE       0.50      0.08      0.14        37\n",
      "         QUE       0.00      0.00      0.00        17\n",
      "          RB       0.78      0.77      0.77       496\n",
      "          RP       0.94      0.96      0.95      1275\n",
      "       RRPCV       0.83      0.86      0.85       844\n",
      "         UNK       0.00      0.00      0.00        55\n",
      "         URL       0.00      0.00      0.00         1\n",
      "         VFM       0.91      0.96      0.93      1346\n",
      "         VNF       0.92      0.91      0.91      2545\n",
      "         VNN       0.92      0.88      0.90      1417\n",
      "          VP       0.91      0.92      0.92      3498\n",
      "         VVF       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.91     49531\n",
      "   macro avg       0.64      0.64      0.64     49531\n",
      "weighted avg       0.91      0.91      0.90     49531\n",
      "\n",
      "\n",
      "üìâ Confusion Matrix (label indices):\n",
      "[[ 416    0    0 ...    0    0    0]\n",
      " [   0  287    0 ...    0    3    0]\n",
      " [   0    0  658 ...    0    2    0]\n",
      " ...\n",
      " [   0    0    1 ... 1253   44    0]\n",
      " [   0    2    1 ...   22 3219    0]\n",
      " [   0    0    0 ...    1    0    0]]\n",
      "\n",
      "üîé Total mismatches found: 1718\n",
      "\n",
      "MISMATCHED SENTENCE 0\n",
      "True Tags : ['POST', 'NNC', 'CM', 'JJ', 'NCV', 'VNF', 'VP', 'RP', 'PRP', 'CM', 'NNC', 'DET', 'DET', 'NNC', 'VP', 'VP', 'JJ', 'JJ', 'JJ', 'NNC', 'VNN', 'VFM', 'FS']\n",
      "Pred Tags : ['POST', 'NNC', 'CM', 'NNC', 'NCV', 'VNF', 'VNF', 'RP', 'PRP', 'CM', 'NNC', 'DET', 'DET', 'NNC', 'VNF', 'VP', 'JJ', 'JJ', 'NNP', 'NNC', 'VNN', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 1\n",
      "True Tags : ['PRP', 'NNC', 'NNP', 'NNC', 'NNC', 'RRPCV', 'VP', 'POST', 'NCV', 'VP', 'JJ', 'NNJ', 'NNC', 'NNC', 'NNP', 'JJ', 'NNC', 'JJ', 'VFM', 'FS']\n",
      "Pred Tags : ['PRP', 'NNC', 'NNP', 'NNC', 'NNC', 'RRPCV', 'VP', 'POST', 'NCV', 'VP', 'JJ', 'NNJ', 'NNC', 'NNC', 'NNP', 'JJ', 'NNC', 'RRPCV', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 2\n",
      "True Tags : ['NDT', 'PRP', 'RRPCV', 'VFM', 'FS']\n",
      "Pred Tags : ['DET', 'NNC', 'RRPCV', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 3\n",
      "True Tags : ['DET', 'NNC', 'NCV', 'VP', 'DET', 'NNC', 'VP', 'JJ', 'NNC', 'VP', 'JJ', 'NNJ', 'NNC', 'NNC', 'NNC', 'NIP', 'NNC', 'CM', 'NNC', 'FS']\n",
      "Pred Tags : ['DET', 'NNC', 'NCV', 'VP', 'DET', 'NNC', 'VP', 'JJ', 'NNC', 'VP', 'JJ', 'JJ', 'NNC', 'NUM', 'NNC', 'NIP', 'NNC', 'CM', 'NVB', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 4\n",
      "True Tags : ['NNP', 'NNP', 'NNC', 'VP', 'NNC', 'JJ', 'NNC', 'RRPCV', 'VNF', 'VNN', 'NNC', 'JJ', 'NNC', 'NNP', 'PUNC', 'NNP', 'NNC', 'VFM', 'FS']\n",
      "Pred Tags : ['NNP', 'NNP', 'NNC', 'VP', 'NNC', 'JJ', 'NNC', 'RRPCV', 'VNF', 'VNN', 'NNC', 'POST', 'NNC', 'NNP', 'PUNC', 'NNP', 'NNC', 'VFM', 'FS']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Evaluate overall metrics using Hugging Face Trainer\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"üîç Evaluation Metrics from trainer.evaluate():\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Step 2: Run predictions\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "predictions = predictions_output.predictions\n",
    "label_ids = predictions_output.label_ids\n",
    "\n",
    "# Step 3: Get most likely tag indices\n",
    "pred_labels = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Step 4: Prepare true and predicted tag names (flattened)\n",
    "true_tags = []\n",
    "predicted_tags = []\n",
    "\n",
    "# Optional: Track mismatches with sentence-level tags\n",
    "mismatches = []\n",
    "\n",
    "for i in range(len(label_ids)):\n",
    "    true_sent = []\n",
    "    pred_sent = []\n",
    "    for true_id, pred_id in zip(label_ids[i], pred_labels[i]):\n",
    "        if true_id != -100:\n",
    "            true_tag = id2tag[true_id]\n",
    "            pred_tag = id2tag[pred_id]\n",
    "            true_tags.append(true_tag)\n",
    "            predicted_tags.append(pred_tag)\n",
    "            true_sent.append(true_tag)\n",
    "            pred_sent.append(pred_tag)\n",
    "    \n",
    "    if true_sent != pred_sent:\n",
    "        mismatches.append((i, true_sent, pred_sent))\n",
    "\n",
    "# Step 5: Classification report\n",
    "unique_tags = sorted(list(set(true_tags + predicted_tags)))\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(true_tags, predicted_tags, labels=unique_tags, zero_division=0))\n",
    "\n",
    "# Step 6: Confusion matrix\n",
    "print(\"\\nüìâ Confusion Matrix (label indices):\")\n",
    "tag2id_filtered = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
    "y_true_ids = [tag2id_filtered[tag] for tag in true_tags]\n",
    "y_pred_ids = [tag2id_filtered[tag] for tag in predicted_tags]\n",
    "cm = confusion_matrix(y_true_ids, y_pred_ids)\n",
    "print(cm)\n",
    "\n",
    "# Step 7: Show a few mismatched sentences\n",
    "print(f\"\\nüîé Total mismatches found: {len(mismatches)}\")\n",
    "for idx, true_sent, pred_sent in mismatches[:5]:  # Limit to 5 for readability\n",
    "    print(f\"\\nMISMATCHED SENTENCE {idx + 1}\")\n",
    "    print(\"True Tags :\", true_sent)\n",
    "    print(\"Pred Tags :\", pred_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710354b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Tag  Train Count  Test Count  Total Count  Tag Origin  Precision  \\\n",
      "0      FS         9010        2252        11262        Both   0.999113   \n",
      "1    PUNC         7055        1838         8893        Both   0.993499   \n",
      "2     PRP         5510        1376         6886        Both   0.974474   \n",
      "3     NIP         3489         857         4346        Both   0.972813   \n",
      "4      CC         2990         687         3677        Both   0.970501   \n",
      "5     DET         4656        1165         5821        Both   0.955556   \n",
      "6     ABB         1608         426         2034        Both   0.943311   \n",
      "7      CM         1796         434         2230        Both   0.942922   \n",
      "8     NUM         4280        1166         5446        Both   0.939167   \n",
      "9      RP         4859        1275         6134        Both   0.937931   \n",
      "10    NNP        20054        5063        25117        Both   0.930195   \n",
      "11   POST        14754        3628        18382        Both   0.926974   \n",
      "12    AUX         1260         300         1560        Both   0.922830   \n",
      "13    VNN         5628        1417         7045        Both   0.919971   \n",
      "14    VNF        10034        2545        12579        Both   0.918052   \n",
      "15     VP        13919        3498        17417        Both   0.912415   \n",
      "16    NNC        49373       12213        61586        Both   0.911968   \n",
      "17    VFM         5203        1346         6549        Both   0.906272   \n",
      "18     JJ        14426        3557        17983        Both   0.851721   \n",
      "19  RRPCV         3267         844         4111        Both   0.833142   \n",
      "20     RB         2099         496         2595        Both   0.775758   \n",
      "21    NCV         3705         927         4632        Both   0.716073   \n",
      "22    JCV         2567         622         3189        Both   0.668863   \n",
      "23    NNJ         5139        1296         6435        Both   0.650937   \n",
      "24    NVB          653         174          827        Both   0.591160   \n",
      "25    QBE          146          37          183        Both   0.500000   \n",
      "26    UNK          300          55          355        Both   0.000000   \n",
      "27    QUE           73          17           90        Both   0.000000   \n",
      "28    NDT           60          14           74        Both   0.000000   \n",
      "29     NN            1           1            2        Both   0.000000   \n",
      "30    FRW            0           1            1   Test Only   0.000000   \n",
      "31    NNp            0           1            1   Test Only   0.000000   \n",
      "32    NVF            0           1            1   Test Only   0.000000   \n",
      "33    URL            0           1            1   Test Only   0.000000   \n",
      "34    VVF            0           1            1   Test Only   0.000000   \n",
      "35    ACV            2           0            2  Train Only   0.000000   \n",
      "36    FSS            1           0            1  Train Only   0.000000   \n",
      "37   NNNP            1           0            1  Train Only   0.000000   \n",
      "38     UH            1           0            1  Train Only   0.000000   \n",
      "39    UNF            1           0            1  Train Only   0.000000   \n",
      "40   VNF[            1           0            1  Train Only   0.000000   \n",
      "41    VNP            1           0            1  Train Only   0.000000   \n",
      "\n",
      "      Recall  F1-Score  \n",
      "0   1.000000  0.999556  \n",
      "1   0.997824  0.995657  \n",
      "2   0.943314  0.958641  \n",
      "3   0.960327  0.966530  \n",
      "4   0.957787  0.964103  \n",
      "5   0.959657  0.957602  \n",
      "6   0.976526  0.959631  \n",
      "7   0.951613  0.947248  \n",
      "8   0.966552  0.952663  \n",
      "9   0.960000  0.948837  \n",
      "10  0.921193  0.925672  \n",
      "11  0.948181  0.937457  \n",
      "12  0.956667  0.939444  \n",
      "13  0.884263  0.901763  \n",
      "14  0.911198  0.914613  \n",
      "15  0.920240  0.916311  \n",
      "16  0.896586  0.904211  \n",
      "17  0.955423  0.930199  \n",
      "18  0.813888  0.832375  \n",
      "19  0.857820  0.845301  \n",
      "20  0.774194  0.774975  \n",
      "21  0.802589  0.756867  \n",
      "22  0.652733  0.660700  \n",
      "23  0.777006  0.708407  \n",
      "24  0.614943  0.602817  \n",
      "25  0.081081  0.139535  \n",
      "26  0.000000  0.000000  \n",
      "27  0.000000  0.000000  \n",
      "28  0.000000  0.000000  \n",
      "29  0.000000  0.000000  \n",
      "30  0.000000  0.000000  \n",
      "31  0.000000  0.000000  \n",
      "32  0.000000  0.000000  \n",
      "33  0.000000  0.000000  \n",
      "34  0.000000  0.000000  \n",
      "35  0.000000  0.000000  \n",
      "36  0.000000  0.000000  \n",
      "37  0.000000  0.000000  \n",
      "38  0.000000  0.000000  \n",
      "39  0.000000  0.000000  \n",
      "40  0.000000  0.000000  \n",
      "41  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Step 1: Extract tags from datasets ---\n",
    "train_tags = [id2tag[tag_id] for sent in tokenized_dataset[\"train\"][\"labels\"] for tag_id in sent if tag_id != -100]\n",
    "test_tags = [id2tag[tag_id] for sent in tokenized_dataset[\"test\"][\"labels\"] for tag_id in sent if tag_id != -100]\n",
    "\n",
    "train_counter = Counter(train_tags)\n",
    "test_counter = Counter(test_tags)\n",
    "\n",
    "train_tag_set = set(train_counter.keys())\n",
    "test_tag_set = set(test_counter.keys())\n",
    "\n",
    "both_tags = sorted(train_tag_set & test_tag_set)\n",
    "train_only_tags = sorted(train_tag_set - test_tag_set)\n",
    "test_only_tags = sorted(test_tag_set - train_tag_set)\n",
    "\n",
    "# --- Step 2: Get classification report as dict ---\n",
    "# Ensure these lists are aligned with predictions\n",
    "report = classification_report(true_tags, predicted_tags, output_dict=True, zero_division=0)\n",
    "\n",
    "# --- Step 3: Combine all tags into rows ---\n",
    "rows = []\n",
    "\n",
    "# Helper function to pull metrics safely\n",
    "def get_metric(tag, metric):\n",
    "    return report[tag][metric] if tag in report else 0.0\n",
    "\n",
    "# Tags in both sets\n",
    "for tag in both_tags:\n",
    "    total = train_counter[tag] + test_counter[tag]\n",
    "    rows.append({\n",
    "        \"Tag\": tag,\n",
    "        \"Train Count\": train_counter[tag],\n",
    "        \"Test Count\": test_counter[tag],\n",
    "        \"Total Count\": total,\n",
    "        \"Tag Origin\": \"Both\",\n",
    "        \"Precision\": get_metric(tag, \"precision\"),\n",
    "        \"Recall\": get_metric(tag, \"recall\"),\n",
    "        \"F1-Score\": get_metric(tag, \"f1-score\")\n",
    "    })\n",
    "\n",
    "# Tags only in training\n",
    "for tag in train_only_tags:\n",
    "    rows.append({\n",
    "        \"Tag\": tag,\n",
    "        \"Train Count\": train_counter[tag],\n",
    "        \"Test Count\": 0,\n",
    "        \"Total Count\": train_counter[tag],\n",
    "        \"Tag Origin\": \"Train Only\",\n",
    "        \"Precision\": 0.0,\n",
    "        \"Recall\": 0.0,\n",
    "        \"F1-Score\": 0.0\n",
    "    })\n",
    "\n",
    "# Tags only in testing\n",
    "for tag in test_only_tags:\n",
    "    rows.append({\n",
    "        \"Tag\": tag,\n",
    "        \"Train Count\": 0,\n",
    "        \"Test Count\": test_counter[tag],\n",
    "        \"Total Count\": test_counter[tag],\n",
    "        \"Tag Origin\": \"Test Only\",\n",
    "        \"Precision\": get_metric(tag, \"precision\"),\n",
    "        \"Recall\": get_metric(tag, \"recall\"),\n",
    "        \"F1-Score\": get_metric(tag, \"f1-score\")\n",
    "    })\n",
    "\n",
    "# --- Step 4: Build DataFrame and sort within each category ---\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Sort within each group\n",
    "df = df.sort_values(by=[\"Tag Origin\", \"Precision\", \"Total Count\"], ascending=[True, False, False]).reset_index(drop=True)\n",
    "\n",
    "# --- Optional: Display or export ---\n",
    "pd.set_option(\"display.max_rows\", None)  # to see all rows\n",
    "print(df)\n",
    "\n",
    "# Optional export\n",
    "#df.to_csv(\"tag_analysis_num-of-ep-1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad9b5c",
   "metadata": {},
   "source": [
    "### Save and Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d75c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"sinhala-pos-xlm-r\")\n",
    "tokenizer.save_pretrained(\"sinhala-pos-xlm-r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pos_pipeline = pipeline(\"token-classification\", model=\"sinhala-pos-xlm-r\", tokenizer=\"sinhala-pos-xlm-r\", aggregation_strategy=\"simple\")\n",
    "\n",
    "sentence = \"‡∂∏‡∂∏ ‡∂¥‡∑è‡∑É‡∑ê‡∂Ω ‡∂∫‡∂∏‡∑í\"\n",
    "tokens = sentence.split()  # Assuming simple whitespace tokenization\n",
    "print(pos_pipeline(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35386bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "GPU name: NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
