{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e252e51b",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e089373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pos_data(path):\n",
    "    dataset = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                # End of a sentence\n",
    "                if tokens:\n",
    "                    dataset.append({\"tokens\": tokens, \"tags\": tags})\n",
    "                    tokens = []\n",
    "                    tags = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    word, tag = parts\n",
    "                    tokens.append(word)\n",
    "                    tags.append(tag)\n",
    "        # Catch the last sentence if no newline at EOF\n",
    "        if tokens:\n",
    "            dataset.append({\"tokens\": tokens, \"tags\": tags})\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a3331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tokens': ['‡∂ä‡∑Å‡∑ä‡∂ª‡∑è‡∂∫‡∂Ω‡∑ä', '‡∂∏‡∑í‡∑É‡∂∫‡∑í‡∂Ω', '‡∂¥‡∑ä‡∂ª‡∑Ñ‡∑è‡∂ª', '‡∑Ä‡∂Ω‡∑í‡∂±‡∑ä', '‡∂¥‡∂Ω‡∑É‡∑ä‡∂≠‡∑ì‡∂±‡∑î‡∑Ä‡∑ù', '4', '‡∂ö‡∑ä', '‡∂∏‡∑í‡∂∫', '‡∂∫‡∂≠‡∑í', '.'], 'tags': ['NNP', 'NNJ', 'NNC', 'CM', 'NNP', 'NUM', 'RP', 'RRPCV', 'VFM', 'FS']}, {'tokens': ['‡∂ú‡∑è‡∑É‡∑è', '‡∂≠‡∑ì‡∂ª‡∂∫‡∑ö‡∂Ø‡∑ì', '.'], 'tags': ['NNP', 'NNP', 'FS']}]\n"
     ]
    }
   ],
   "source": [
    "print(load_pos_data(\"sinhala_pos.txt\")[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307ac143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "# all_data = load_pos_data(\"sinhala_pos.txt\")\n",
    "# random.shuffle(all_data)\n",
    "\n",
    "# # Optional: 80% train, 20% test split\n",
    "# split_idx = int(0.8 * len(all_data))\n",
    "# train_data = all_data[:split_idx]\n",
    "# test_data = all_data[split_idx:]\n",
    "\n",
    "# dataset = DatasetDict({\n",
    "#     \"train\": Dataset.from_list(train_data),\n",
    "#     \"test\": Dataset.from_list(test_data),\n",
    "# })\n",
    "\n",
    "data = load_pos_data(\"sinhala_pos.txt\")\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75e430",
   "metadata": {},
   "source": [
    "### tag2id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58584ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set(tag for example in data for tag in example[\"tags\"])\n",
    "\n",
    "tag2id = {tag: i for i, tag in enumerate(sorted(unique_tags))}\n",
    "label_list = list(tag2id.keys())\n",
    "\n",
    "id2tag = {i: tag for tag, i in tag2id.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac2906",
   "metadata": {},
   "source": [
    "### Tokenize and Align Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263ae3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9040/9040 [00:09<00:00, 909.46 examples/s] \n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2261/2261 [00:02<00:00, 1042.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"tokens\"], \n",
    "        is_split_into_words=True, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\",      # Pad to max length of the model or your max_length param\n",
    "        max_length=256,            # or any max_length you want (optional)\n",
    "        return_tensors=None        # don't convert to tensors here; Trainer does it later\n",
    "    )\n",
    "    \n",
    "    word_ids = tokenized.word_ids()\n",
    "    labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            labels.append(tag2id[example[\"tags\"][word_idx]])\n",
    "        else:\n",
    "            # Label only the first sub-token\n",
    "            labels.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db6892",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629a9d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    num_labels=len(tag2id),\n",
    "    id2label=id2tag,\n",
    "    label2id=tag2id,\n",
    "    local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ccb24e",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9231ff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_25372\\1272681515.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2260' max='2260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2260/2260 6:01:14, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.317093</td>\n",
       "      <td>0.911738</td>\n",
       "      <td>0.911807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.283806</td>\n",
       "      <td>0.920654</td>\n",
       "      <td>0.921113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.275995</td>\n",
       "      <td>0.923030</td>\n",
       "      <td>0.923303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229400</td>\n",
       "      <td>0.272975</td>\n",
       "      <td>0.923538</td>\n",
       "      <td>0.923902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9622    0.9745    0.9683       470\n",
      "         AUX     0.9785    0.9695    0.9740       328\n",
      "          CC     0.9743    0.9639    0.9691       748\n",
      "          CM     0.9545    0.9481    0.9513       443\n",
      "         DET     0.9704    0.9704    0.9704      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.6915    0.7365    0.7133       630\n",
      "          JJ     0.8674    0.8256    0.8460      3652\n",
      "         NCV     0.7721    0.8462    0.8074       949\n",
      "         NDT     0.0000    0.0000    0.0000        15\n",
      "         NIP     0.9643    0.9774    0.9708       884\n",
      "         NNC     0.9235    0.8963    0.9097     12249\n",
      "         NNJ     0.6636    0.7877    0.7204      1300\n",
      "         NNP     0.9163    0.9311    0.9236      4806\n",
      "         NUM     0.9549    0.9429    0.9489      1033\n",
      "         NVB     0.5833    0.7226    0.6455       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9295    0.9509    0.9401      3647\n",
      "         PRP     0.9809    0.9462    0.9633      1413\n",
      "        PUNC     0.9938    0.9977    0.9958      1776\n",
      "         QBE     0.7250    0.5918    0.6517        49\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.8466    0.7695    0.8062       538\n",
      "          RP     0.9543    0.9454    0.9498      1172\n",
      "       RRPCV     0.8647    0.8563    0.8605       821\n",
      "         UNK     0.8571    0.2791    0.4211        43\n",
      "         VFM     0.9341    0.9384    0.9362      1314\n",
      "         VNF     0.9136    0.9143    0.9139      2520\n",
      "         VNN     0.8956    0.9069    0.9012      1428\n",
      "          VP     0.9043    0.9386    0.9211      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9117     49240\n",
      "   macro avg     0.7734    0.7589    0.7606     49240\n",
      "weighted avg     0.9129    0.9117    0.9118     49240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9702    0.9702    0.9702       470\n",
      "         AUX     0.9846    0.9756    0.9801       328\n",
      "          CC     0.9771    0.9679    0.9725       748\n",
      "          CM     0.9611    0.9481    0.9545       443\n",
      "         DET     0.9697    0.9782    0.9740      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.7052    0.7746    0.7383       630\n",
      "          JJ     0.8701    0.8453    0.8575      3652\n",
      "         NCV     0.8012    0.8493    0.8246       949\n",
      "         NDT     0.7500    0.2000    0.3158        15\n",
      "         NIP     0.9686    0.9774    0.9730       884\n",
      "         NNC     0.9295    0.9067    0.9180     12249\n",
      "         NNJ     0.6795    0.8123    0.7400      1300\n",
      "         NNP     0.9340    0.9417    0.9378      4806\n",
      "         NUM     0.9570    0.9477    0.9523      1033\n",
      "         NVB     0.6464    0.7548    0.6964       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9479    0.9487    0.9483      3647\n",
      "         PRP     0.9831    0.9490    0.9658      1413\n",
      "        PUNC     0.9961    0.9977    0.9969      1776\n",
      "         QBE     0.6346    0.6735    0.6535        49\n",
      "         QUE     0.3333    0.1765    0.2308        17\n",
      "          RB     0.8703    0.8234    0.8462       538\n",
      "          RP     0.9567    0.9437    0.9502      1172\n",
      "       RRPCV     0.9117    0.8551    0.8825       821\n",
      "         UNK     0.9512    0.9070    0.9286        43\n",
      "         VFM     0.9361    0.9368    0.9365      1314\n",
      "         VNF     0.9189    0.9262    0.9225      2520\n",
      "         VNN     0.8988    0.9139    0.9062      1428\n",
      "          VP     0.9180    0.9418    0.9297      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9207     49240\n",
      "   macro avg     0.8181    0.8014    0.8033     49240\n",
      "weighted avg     0.9223    0.9207    0.9211     49240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9705    0.9809    0.9757       470\n",
      "         AUX     0.9876    0.9726    0.9800       328\n",
      "          CC     0.9772    0.9733    0.9752       748\n",
      "          CM     0.9594    0.9594    0.9594       443\n",
      "         DET     0.9632    0.9817    0.9724      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.6953    0.7968    0.7426       630\n",
      "          JJ     0.8756    0.8478    0.8614      3652\n",
      "         NCV     0.8295    0.8303    0.8299       949\n",
      "         NDT     0.6154    0.5333    0.5714        15\n",
      "         NIP     0.9622    0.9796    0.9709       884\n",
      "         NNC     0.9329    0.9091    0.9208     12249\n",
      "         NNJ     0.7238    0.7923    0.7565      1300\n",
      "         NNP     0.9344    0.9422    0.9383      4806\n",
      "         NUM     0.9416    0.9681    0.9547      1033\n",
      "         NVB     0.6283    0.7742    0.6936       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9381    0.9600    0.9489      3647\n",
      "         PRP     0.9846    0.9483    0.9661      1413\n",
      "        PUNC     0.9949    0.9977    0.9963      1776\n",
      "         QBE     0.6735    0.6735    0.6735        49\n",
      "         QUE     0.3571    0.2941    0.3226        17\n",
      "          RB     0.8281    0.8327    0.8304       538\n",
      "          RP     0.9537    0.9488    0.9512      1172\n",
      "       RRPCV     0.9225    0.8551    0.8875       821\n",
      "         UNK     0.9524    0.9302    0.9412        43\n",
      "         VFM     0.9328    0.9399    0.9363      1314\n",
      "         VNF     0.9199    0.9302    0.9250      2520\n",
      "         VNN     0.9148    0.9027    0.9087      1428\n",
      "          VP     0.9202    0.9438    0.9319      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9230     49240\n",
      "   macro avg     0.8158    0.8193    0.8168     49240\n",
      "weighted avg     0.9240    0.9230    0.9233     49240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9705    0.9809    0.9757       470\n",
      "         AUX     0.9846    0.9726    0.9785       328\n",
      "          CC     0.9745    0.9719    0.9732       748\n",
      "          CM     0.9593    0.9571    0.9582       443\n",
      "         DET     0.9690    0.9817    0.9753      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.7176    0.7825    0.7487       630\n",
      "          JJ     0.8824    0.8401    0.8607      3652\n",
      "         NCV     0.8020    0.8535    0.8270       949\n",
      "         NDT     0.6154    0.5333    0.5714        15\n",
      "         NIP     0.9601    0.9808    0.9703       884\n",
      "         NNC     0.9368    0.9075    0.9219     12249\n",
      "         NNJ     0.7047    0.8169    0.7567      1300\n",
      "         NNP     0.9327    0.9459    0.9393      4806\n",
      "         NUM     0.9433    0.9671    0.9551      1033\n",
      "         NVB     0.6559    0.7871    0.7155       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9427    0.9559    0.9492      3647\n",
      "         PRP     0.9810    0.9505    0.9655      1413\n",
      "        PUNC     0.9955    0.9977    0.9966      1776\n",
      "         QBE     0.7045    0.6327    0.6667        49\n",
      "         QUE     0.4375    0.4118    0.4242        17\n",
      "          RB     0.8439    0.8439    0.8439       538\n",
      "          RP     0.9545    0.9497    0.9521      1172\n",
      "       RRPCV     0.8932    0.8660    0.8794       821\n",
      "         UNK     0.9524    0.9302    0.9412        43\n",
      "         VFM     0.9276    0.9452    0.9363      1314\n",
      "         VNF     0.9170    0.9341    0.9255      2520\n",
      "         VNN     0.9086    0.9048    0.9067      1428\n",
      "          VP     0.9281    0.9394    0.9337      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9235     49240\n",
      "   macro avg     0.8192    0.8239    0.8209     49240\n",
      "weighted avg     0.9249    0.9235    0.9239     49240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2260, training_loss=0.35532055069914964, metrics={'train_runtime': 21688.0973, 'train_samples_per_second': 1.667, 'train_steps_per_second': 0.104, 'total_flos': 4725953826324480.0, 'train_loss': 0.35532055069914964, 'epoch': 4.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "# from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     preds = np.argmax(p.predictions, axis=2)\n",
    "#     labels = p.label_ids\n",
    "\n",
    "#     true_preds = [\n",
    "#         [id2tag[p] for (p, l) in zip(pred_seq, label_seq) if l != -100]\n",
    "#         for pred_seq, label_seq in zip(preds, labels)\n",
    "#     ]\n",
    "#     true_labels = [\n",
    "#         [id2tag[l] for (p, l) in zip(pred_seq, label_seq) if l != -100]\n",
    "#         for pred_seq, label_seq in zip(preds, labels)\n",
    "#     ]\n",
    "\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "#         \"report\": classification_report(true_labels, true_preds),\n",
    "#     }\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=2)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Convert IDs to tag names, skip padding (-100)\n",
    "\n",
    "    \n",
    "    true_preds = [\n",
    "        id2tag[p] for pred_seq, label_seq in zip(preds, labels)\n",
    "        for p, l in zip(pred_seq, label_seq) if l != -100\n",
    "    ]\n",
    "    true_labels = [\n",
    "        id2tag[l] for pred_seq, label_seq in zip(preds, labels)\n",
    "        for p, l in zip(pred_seq, label_seq) if l != -100\n",
    "    ]\n",
    "\n",
    "    # Optional: print detailed report to console (not return)\n",
    "    print(classification_report(true_labels, true_preds, digits=4))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds, average=\"weighted\"),\n",
    "        # Avoid printing report here in returned dict ‚Äî it's too long\n",
    "        # Use print manually if needed:\n",
    "        # print(classification_report(true_labels, true_preds))\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pos-xlm-r\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84beb556",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f613e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9705    0.9809    0.9757       470\n",
      "         AUX     0.9846    0.9726    0.9785       328\n",
      "          CC     0.9745    0.9719    0.9732       748\n",
      "          CM     0.9593    0.9571    0.9582       443\n",
      "         DET     0.9690    0.9817    0.9753      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.7176    0.7825    0.7487       630\n",
      "          JJ     0.8824    0.8401    0.8607      3652\n",
      "         NCV     0.8020    0.8535    0.8270       949\n",
      "         NDT     0.6154    0.5333    0.5714        15\n",
      "         NIP     0.9601    0.9808    0.9703       884\n",
      "         NNC     0.9368    0.9075    0.9219     12249\n",
      "         NNJ     0.7047    0.8169    0.7567      1300\n",
      "         NNP     0.9327    0.9459    0.9393      4806\n",
      "         NUM     0.9433    0.9671    0.9551      1033\n",
      "         NVB     0.6559    0.7871    0.7155       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9427    0.9559    0.9492      3647\n",
      "         PRP     0.9810    0.9505    0.9655      1413\n",
      "        PUNC     0.9955    0.9977    0.9966      1776\n",
      "         QBE     0.7045    0.6327    0.6667        49\n",
      "         QUE     0.4375    0.4118    0.4242        17\n",
      "          RB     0.8439    0.8439    0.8439       538\n",
      "          RP     0.9545    0.9497    0.9521      1172\n",
      "       RRPCV     0.8932    0.8660    0.8794       821\n",
      "         UNK     0.9524    0.9302    0.9412        43\n",
      "         VFM     0.9276    0.9452    0.9363      1314\n",
      "         VNF     0.9170    0.9341    0.9255      2520\n",
      "         VNN     0.9086    0.9048    0.9067      1428\n",
      "          VP     0.9281    0.9394    0.9337      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9235     49240\n",
      "   macro avg     0.8192    0.8239    0.8209     49240\n",
      "weighted avg     0.9249    0.9235    0.9239     49240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27297502756118774,\n",
       " 'eval_accuracy': 0.9235377741673436,\n",
       " 'eval_f1': 0.9239023109313633,\n",
       " 'eval_runtime': 112.2575,\n",
       " 'eval_samples_per_second': 20.141,\n",
       " 'eval_steps_per_second': 1.265,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73480896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9705    0.9809    0.9757       470\n",
      "         AUX     0.9846    0.9726    0.9785       328\n",
      "          CC     0.9745    0.9719    0.9732       748\n",
      "          CM     0.9593    0.9571    0.9582       443\n",
      "         DET     0.9690    0.9817    0.9753      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.7176    0.7825    0.7487       630\n",
      "          JJ     0.8824    0.8401    0.8607      3652\n",
      "         NCV     0.8020    0.8535    0.8270       949\n",
      "         NDT     0.6154    0.5333    0.5714        15\n",
      "         NIP     0.9601    0.9808    0.9703       884\n",
      "         NNC     0.9368    0.9075    0.9219     12249\n",
      "         NNJ     0.7047    0.8169    0.7567      1300\n",
      "         NNP     0.9327    0.9459    0.9393      4806\n",
      "         NUM     0.9433    0.9671    0.9551      1033\n",
      "         NVB     0.6559    0.7871    0.7155       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9427    0.9559    0.9492      3647\n",
      "         PRP     0.9810    0.9505    0.9655      1413\n",
      "        PUNC     0.9955    0.9977    0.9966      1776\n",
      "         QBE     0.7045    0.6327    0.6667        49\n",
      "         QUE     0.4375    0.4118    0.4242        17\n",
      "          RB     0.8439    0.8439    0.8439       538\n",
      "          RP     0.9545    0.9497    0.9521      1172\n",
      "       RRPCV     0.8932    0.8660    0.8794       821\n",
      "         UNK     0.9524    0.9302    0.9412        43\n",
      "         VFM     0.9276    0.9452    0.9363      1314\n",
      "         VNF     0.9170    0.9341    0.9255      2520\n",
      "         VNN     0.9086    0.9048    0.9067      1428\n",
      "          VP     0.9281    0.9394    0.9337      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9235     49240\n",
      "   macro avg     0.8192    0.8239    0.8209     49240\n",
      "weighted avg     0.9249    0.9235    0.9239     49240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB       0.97      0.98      0.98       470\n",
      "         AUX       0.98      0.97      0.98       328\n",
      "          CC       0.97      0.97      0.97       748\n",
      "          CM       0.96      0.96      0.96       443\n",
      "         DET       0.97      0.98      0.98      1147\n",
      "          FS       1.00      1.00      1.00      2256\n",
      "         JCV       0.72      0.78      0.75       630\n",
      "          JJ       0.88      0.84      0.86      3652\n",
      "         NCV       0.80      0.85      0.83       949\n",
      "         NDT       0.62      0.53      0.57        15\n",
      "         NIP       0.96      0.98      0.97       884\n",
      "         NNC       0.94      0.91      0.92     12249\n",
      "         NNJ       0.70      0.82      0.76      1300\n",
      "         NNP       0.93      0.95      0.94      4806\n",
      "         NUM       0.94      0.97      0.96      1033\n",
      "         NVB       0.66      0.79      0.72       155\n",
      "         NVF       0.00      0.00      0.00         1\n",
      "        POST       0.94      0.96      0.95      3647\n",
      "         PRP       0.98      0.95      0.97      1413\n",
      "        PUNC       1.00      1.00      1.00      1776\n",
      "         QBE       0.70      0.63      0.67        49\n",
      "         QUE       0.44      0.41      0.42        17\n",
      "          RB       0.84      0.84      0.84       538\n",
      "          RP       0.95      0.95      0.95      1172\n",
      "       RRPCV       0.89      0.87      0.88       821\n",
      "         UNK       0.95      0.93      0.94        43\n",
      "         VFM       0.93      0.95      0.94      1314\n",
      "         VNF       0.92      0.93      0.93      2520\n",
      "         VNN       0.91      0.90      0.91      1428\n",
      "          VP       0.93      0.94      0.93      3435\n",
      "         VVF       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92     49240\n",
      "   macro avg       0.82      0.82      0.82     49240\n",
      "weighted avg       0.92      0.92      0.92     49240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "preds = predictions_output.predictions.argmax(-1)\n",
    "labels = predictions_output.label_ids\n",
    "\n",
    "# Flatten predictions, ignoring -100\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for pred_seq, label_seq in zip(preds, labels):\n",
    "    for pred, label in zip(pred_seq, label_seq):\n",
    "        if label != -100:\n",
    "            true_labels.append(label)\n",
    "            predicted_labels.append(pred)\n",
    "\n",
    "# Dynamically detect used label IDs\n",
    "used_label_ids = sorted(set(true_labels + predicted_labels))\n",
    "\n",
    "# Match label IDs to tag names\n",
    "target_names = [id2tag[i] for i in used_label_ids]\n",
    "\n",
    "# Evaluate safely with matching label set\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    predicted_labels,\n",
    "    labels=used_label_ids,\n",
    "    target_names=target_names,\n",
    "    zero_division=0  # prevents warnings for unseen labels\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f32102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9705    0.9809    0.9757       470\n",
      "         AUX     0.9846    0.9726    0.9785       328\n",
      "          CC     0.9745    0.9719    0.9732       748\n",
      "          CM     0.9593    0.9571    0.9582       443\n",
      "         DET     0.9690    0.9817    0.9753      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.7176    0.7825    0.7487       630\n",
      "          JJ     0.8824    0.8401    0.8607      3652\n",
      "         NCV     0.8020    0.8535    0.8270       949\n",
      "         NDT     0.6154    0.5333    0.5714        15\n",
      "         NIP     0.9601    0.9808    0.9703       884\n",
      "         NNC     0.9368    0.9075    0.9219     12249\n",
      "         NNJ     0.7047    0.8169    0.7567      1300\n",
      "         NNP     0.9327    0.9459    0.9393      4806\n",
      "         NUM     0.9433    0.9671    0.9551      1033\n",
      "         NVB     0.6559    0.7871    0.7155       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9427    0.9559    0.9492      3647\n",
      "         PRP     0.9810    0.9505    0.9655      1413\n",
      "        PUNC     0.9955    0.9977    0.9966      1776\n",
      "         QBE     0.7045    0.6327    0.6667        49\n",
      "         QUE     0.4375    0.4118    0.4242        17\n",
      "          RB     0.8439    0.8439    0.8439       538\n",
      "          RP     0.9545    0.9497    0.9521      1172\n",
      "       RRPCV     0.8932    0.8660    0.8794       821\n",
      "         UNK     0.9524    0.9302    0.9412        43\n",
      "         VFM     0.9276    0.9452    0.9363      1314\n",
      "         VNF     0.9170    0.9341    0.9255      2520\n",
      "         VNN     0.9086    0.9048    0.9067      1428\n",
      "          VP     0.9281    0.9394    0.9337      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9235     49240\n",
      "   macro avg     0.8192    0.8239    0.8209     49240\n",
      "weighted avg     0.9249    0.9235    0.9239     49240\n",
      "\n",
      "üîç Evaluation Metrics from trainer.evaluate():\n",
      "eval_loss: 0.2730\n",
      "eval_accuracy: 0.9235\n",
      "eval_f1: 0.9239\n",
      "eval_runtime: 111.1152\n",
      "eval_samples_per_second: 20.3480\n",
      "eval_steps_per_second: 1.2780\n",
      "epoch: 4.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9705    0.9809    0.9757       470\n",
      "         AUX     0.9846    0.9726    0.9785       328\n",
      "          CC     0.9745    0.9719    0.9732       748\n",
      "          CM     0.9593    0.9571    0.9582       443\n",
      "         DET     0.9690    0.9817    0.9753      1147\n",
      "          FS     1.0000    0.9996    0.9998      2256\n",
      "         JCV     0.7176    0.7825    0.7487       630\n",
      "          JJ     0.8824    0.8401    0.8607      3652\n",
      "         NCV     0.8020    0.8535    0.8270       949\n",
      "         NDT     0.6154    0.5333    0.5714        15\n",
      "         NIP     0.9601    0.9808    0.9703       884\n",
      "         NNC     0.9368    0.9075    0.9219     12249\n",
      "         NNJ     0.7047    0.8169    0.7567      1300\n",
      "         NNP     0.9327    0.9459    0.9393      4806\n",
      "         NUM     0.9433    0.9671    0.9551      1033\n",
      "         NVB     0.6559    0.7871    0.7155       155\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9427    0.9559    0.9492      3647\n",
      "         PRP     0.9810    0.9505    0.9655      1413\n",
      "        PUNC     0.9955    0.9977    0.9966      1776\n",
      "         QBE     0.7045    0.6327    0.6667        49\n",
      "         QUE     0.4375    0.4118    0.4242        17\n",
      "          RB     0.8439    0.8439    0.8439       538\n",
      "          RP     0.9545    0.9497    0.9521      1172\n",
      "       RRPCV     0.8932    0.8660    0.8794       821\n",
      "         UNK     0.9524    0.9302    0.9412        43\n",
      "         VFM     0.9276    0.9452    0.9363      1314\n",
      "         VNF     0.9170    0.9341    0.9255      2520\n",
      "         VNN     0.9086    0.9048    0.9067      1428\n",
      "          VP     0.9281    0.9394    0.9337      3435\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9235     49240\n",
      "   macro avg     0.8192    0.8239    0.8209     49240\n",
      "weighted avg     0.9249    0.9235    0.9239     49240\n",
      "\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB       0.97      0.98      0.98       470\n",
      "         AUX       0.98      0.97      0.98       328\n",
      "          CC       0.97      0.97      0.97       748\n",
      "          CM       0.96      0.96      0.96       443\n",
      "         DET       0.97      0.98      0.98      1147\n",
      "          FS       1.00      1.00      1.00      2256\n",
      "         JCV       0.72      0.78      0.75       630\n",
      "          JJ       0.88      0.84      0.86      3652\n",
      "         NCV       0.80      0.85      0.83       949\n",
      "         NDT       0.62      0.53      0.57        15\n",
      "         NIP       0.96      0.98      0.97       884\n",
      "         NNC       0.94      0.91      0.92     12249\n",
      "         NNJ       0.70      0.82      0.76      1300\n",
      "         NNP       0.93      0.95      0.94      4806\n",
      "         NUM       0.94      0.97      0.96      1033\n",
      "         NVB       0.66      0.79      0.72       155\n",
      "         NVF       0.00      0.00      0.00         1\n",
      "        POST       0.94      0.96      0.95      3647\n",
      "         PRP       0.98      0.95      0.97      1413\n",
      "        PUNC       1.00      1.00      1.00      1776\n",
      "         QBE       0.70      0.63      0.67        49\n",
      "         QUE       0.44      0.41      0.42        17\n",
      "          RB       0.84      0.84      0.84       538\n",
      "          RP       0.95      0.95      0.95      1172\n",
      "       RRPCV       0.89      0.87      0.88       821\n",
      "         UNK       0.95      0.93      0.94        43\n",
      "         VFM       0.93      0.95      0.94      1314\n",
      "         VNF       0.92      0.93      0.93      2520\n",
      "         VNN       0.91      0.90      0.91      1428\n",
      "          VP       0.93      0.94      0.93      3435\n",
      "         VVF       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92     49240\n",
      "   macro avg       0.82      0.82      0.82     49240\n",
      "weighted avg       0.92      0.92      0.92     49240\n",
      "\n",
      "\n",
      "üìâ Confusion Matrix (label indices):\n",
      "[[  461     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     5     1     0     0     0     0     2     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0   319     0     2     0     0     0     0     0     0     0     1\n",
      "      0     0     2     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     2     0]\n",
      " [    0     0   727     0     0     0     1     0     0     0     3     0\n",
      "      0     0     0     0     0    13     0     0     0     0     0     0\n",
      "      0     0     0     1     0     3     0]\n",
      " [    0     0     2   424     0     0     0     0     0     0     0     0\n",
      "      0     0     4     0     0     0     0     0     0     0     0    13\n",
      "      0     0     0     0     0     0     0]\n",
      " [    1     0     0     0  1126     0     0     2     0     1     0     5\n",
      "      0     0     1     0     0     3     0     0     0     0     2     5\n",
      "      0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0  2255     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     1     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0   493    10    49     0     1    18\n",
      "      0     1     0     0     0     0     0     0     0     0     0     0\n",
      "     46     0     0    11     1     0     0]\n",
      " [    0     1     0     0    12     0    24  3068     9     0     1   133\n",
      "    192   113    15     0     0    31     2     0     3     0    14     6\n",
      "      3     0     0     0     0    25     0]\n",
      " [    0     0     0     0     0     0    38     1   810     0     0    82\n",
      "      3     1     0     0     0     0     0     0     0     0     1     0\n",
      "     12     0     0     1     0     0     0]\n",
      " [    0     0     0     0     6     0     0     0     0     8     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     1     0     0     0     0     0     0     0   867     5\n",
      "      0     0     0     0     0     4     0     1     0     0     0     0\n",
      "      0     0     0     5     0     1     0]\n",
      " [    2     1     1     3    11     0    45   183   114     2     4 11116\n",
      "    213   167    23    26     0    87    13     2     5     1    55     2\n",
      "      8     2    25    38    60    40     0]\n",
      " [    0     0     1     0     0     0     0    83     6     0     0   123\n",
      "   1062    23     0     0     0     0     0     1     0     0     0     0\n",
      "      0     0     0     0     1     0     0]\n",
      " [    3     0     0     1     0     0     1    54     0     0     0   140\n",
      "     26  4546     7     0     0     4     5     0     1     0     0     1\n",
      "      0     0     0     7     2     8     0]\n",
      " [    0     1     0     2     0     0     1     9     0     0     0    17\n",
      "      0     0   999     1     0     0     2     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     1     0     0     0     0     0     0     0     0     1    12\n",
      "      0     0     1   122     0     7     1     0     0     0     0     0\n",
      "      0     0     8     1     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     6     1     0     0     1    16     1     0     9    38\n",
      "      1     1     1    18     0  3486     3     0     0     0     4     5\n",
      "      7     0     0    18     3    28     0]\n",
      " [    1     0     1     0     3     0     0     0     0     1     0    40\n",
      "      1     4     0     0     0    16  1343     0     0     0     2     0\n",
      "      0     0     0     0     1     0     0]\n",
      " [    3     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     1     0     0     0     0     0  1772     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     1     2\n",
      "      0     1     0     0     0     3     0     0    31     8     1     0\n",
      "      0     0     0     0     0     2     0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     1     0\n",
      "      0     1     0     0     0     0     0     0     4     7     1     2\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     1     0     3     0     4    16     0     0     0    49\n",
      "      0     0     0     0     0     6     0     0     0     0   454     4\n",
      "      0     0     0     1     0     0     0]\n",
      " [    1     0     1     9     0     0     1     7     0     0     4     3\n",
      "      0     1     2     0     0     5     0     1     0     0     1  1113\n",
      "      0     0     0    20     0     3     0]\n",
      " [    0     0     0     0     0     0    64     1    14     0     1     5\n",
      "      0     0     1     0     0     3     0     0     0     0     0     0\n",
      "    711     0     0    15     2     4     0]\n",
      " [    3     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0    40     0     0     0     0     0]\n",
      " [    0     1     0     0     0     0     0     0     0     0     2     2\n",
      "      0     1     1    19     0     0     0     0     0     0     0     0\n",
      "      0     0  1242     6    15    25     0]\n",
      " [    0     0     0     0     0     0    10     8     2     0     3    16\n",
      "      3     3     1     0     0    15     0     0     0     0     3    11\n",
      "      6     0     6  2354    18    61     0]\n",
      " [    0     0     4     0     1     0     0     0     2     0     0    32\n",
      "      5     1     0     0     0     1     0     0     0     0     0     0\n",
      "      1     0    22    21  1292    46     0]\n",
      " [    0     0     1     0     0     0     4    19     3     0     5    24\n",
      "      1     4     0     0     0    14     0     0     0     0     0     1\n",
      "      2     0    36    68    26  3227     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     1     0     0]]\n",
      "\n",
      "üîé Total mismatches found: 1566\n",
      "\n",
      "MISMATCHED SENTENCE 2\n",
      "True Tags : ['NUM', 'PUNC', 'NNJ', 'JJ', 'NNP', 'NNP', 'NNJ', 'NNC', 'NNP', 'NNC', 'ABB', 'PUNC', 'ABB', 'PUNC', 'ABB', 'PUNC', 'NNC', 'NNP', 'NNP', 'JJ', 'NNJ', 'NNC', 'VNF', 'NNJ', 'JJ', 'NNJ', 'RP', 'NCV', 'VNF', 'VNF', 'VFM', 'FS']\n",
      "Pred Tags : ['NUM', 'PUNC', 'NNJ', 'NNC', 'NNP', 'NNP', 'NNJ', 'NNC', 'NNP', 'NNC', 'ABB', 'PUNC', 'ABB', 'PUNC', 'ABB', 'PUNC', 'POST', 'JJ', 'NNC', 'JJ', 'NNJ', 'NNC', 'VNF', 'NNJ', 'NNC', 'NNC', 'RP', 'NCV', 'VNF', 'VNF', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 3\n",
      "True Tags : ['NNJ', 'NNC', 'VP', 'JJ', 'NNJ', 'NNJ', 'NNC', 'NNC', 'JJ', 'NNC', 'FS']\n",
      "Pred Tags : ['NNJ', 'NNC', 'VP', 'JJ', 'JJ', 'NNJ', 'NNC', 'NNC', 'JJ', 'NNC', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 4\n",
      "True Tags : ['NUM', 'PUNC', 'POST', 'NNC', 'VNF', 'VP', 'AUX', 'NNC', 'NNC', 'VNF', 'CC', 'JJ', 'CC', 'JJ', 'NNC', 'NVB', 'FS']\n",
      "Pred Tags : ['NUM', 'PUNC', 'POST', 'NNC', 'VNF', 'VP', 'AUX', 'NNC', 'NCV', 'VNF', 'CC', 'JJ', 'CC', 'JJ', 'NNC', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 5\n",
      "True Tags : ['NNP', 'NNC', 'NNC', 'NNJ', 'NNC', 'VP', 'NNP', 'NNP', 'NNP', 'JJ', 'NNC', 'VP', 'POST', 'NCV', 'VNF', 'NIP', 'FS']\n",
      "Pred Tags : ['NNP', 'NNC', 'NNP', 'NNC', 'NNC', 'VP', 'NNP', 'NNP', 'NNP', 'JJ', 'NNC', 'VP', 'POST', 'NCV', 'VNF', 'NIP', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 6\n",
      "True Tags : ['JJ', 'NNC', 'JJ', 'NNC', 'NNC', 'RRPCV', 'VP', 'JJ', 'NNC', 'PRP', 'VFM', 'FS']\n",
      "Pred Tags : ['JJ', 'NNP', 'JJ', 'NNC', 'NNC', 'RRPCV', 'VP', 'JJ', 'NNC', 'PRP', 'VFM', 'FS']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Evaluate overall metrics using Hugging Face Trainer\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"üîç Evaluation Metrics from trainer.evaluate():\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Step 2: Run predictions\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "predictions = predictions_output.predictions\n",
    "label_ids = predictions_output.label_ids\n",
    "\n",
    "# Step 3: Get most likely tag indices\n",
    "pred_labels = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Step 4: Prepare true and predicted tag names (flattened)\n",
    "true_tags = []\n",
    "predicted_tags = []\n",
    "\n",
    "# Optional: Track mismatches with sentence-level tags\n",
    "mismatches = []\n",
    "\n",
    "for i in range(len(label_ids)):\n",
    "    true_sent = []\n",
    "    pred_sent = []\n",
    "    for true_id, pred_id in zip(label_ids[i], pred_labels[i]):\n",
    "        if true_id != -100:\n",
    "            true_tag = id2tag[true_id]\n",
    "            pred_tag = id2tag[pred_id]\n",
    "            true_tags.append(true_tag)\n",
    "            predicted_tags.append(pred_tag)\n",
    "            true_sent.append(true_tag)\n",
    "            pred_sent.append(pred_tag)\n",
    "    \n",
    "    if true_sent != pred_sent:\n",
    "        mismatches.append((i, true_sent, pred_sent))\n",
    "\n",
    "# Step 5: Classification report\n",
    "unique_tags = sorted(list(set(true_tags + predicted_tags)))\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(true_tags, predicted_tags, labels=unique_tags, zero_division=0))\n",
    "\n",
    "# Step 6: Confusion matrix\n",
    "print(\"\\nüìâ Confusion Matrix (label indices):\")\n",
    "tag2id_filtered = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
    "y_true_ids = [tag2id_filtered[tag] for tag in true_tags]\n",
    "y_pred_ids = [tag2id_filtered[tag] for tag in predicted_tags]\n",
    "cm = confusion_matrix(y_true_ids, y_pred_ids)\n",
    "print(cm)\n",
    "\n",
    "# Step 7: Show a few mismatched sentences\n",
    "print(f\"\\nüîé Total mismatches found: {len(mismatches)}\")\n",
    "for idx, true_sent, pred_sent in mismatches[:5]:  # Limit to 5 for readability\n",
    "    print(f\"\\nMISMATCHED SENTENCE {idx + 1}\")\n",
    "    print(\"True Tags :\", true_sent)\n",
    "    print(\"Pred Tags :\", pred_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710354b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Tag  Train Count  Test Count  Total Count  Tag Origin  Precision  \\\n",
      "0      FS         9006        2256        11262        Both   1.000000   \n",
      "1    PUNC         7117        1776         8893        Both   0.995506   \n",
      "2     AUX         1232         328         1560        Both   0.984568   \n",
      "3     PRP         5473        1413         6886        Both   0.981008   \n",
      "4      CC         2929         748         3677        Both   0.974531   \n",
      "5     ABB         1564         470         2034        Both   0.970526   \n",
      "6     DET         4674        1147         5821        Both   0.969019   \n",
      "7     NIP         3462         884         4346        Both   0.960133   \n",
      "8      CM         1787         443         2230        Both   0.959276   \n",
      "9      RP         4962        1172         6134        Both   0.954545   \n",
      "10    UNK          312          43          355        Both   0.952381   \n",
      "11    NUM         4413        1033         5446        Both   0.943343   \n",
      "12   POST        14735        3647        18382        Both   0.942672   \n",
      "13    NNC        49337       12249        61586        Both   0.936794   \n",
      "14    NNP        20311        4806        25117        Both   0.932704   \n",
      "15     VP        13982        3435        17417        Both   0.928099   \n",
      "16    VFM         5235        1314         6549        Both   0.927558   \n",
      "17    VNF        10059        2520        12579        Both   0.917024   \n",
      "18    VNN         5617        1428         7045        Both   0.908579   \n",
      "19  RRPCV         3290         821         4111        Both   0.893216   \n",
      "20     JJ        14331        3652        17983        Both   0.882370   \n",
      "21     RB         2057         538         2595        Both   0.843866   \n",
      "22    NCV         3683         949         4632        Both   0.801980   \n",
      "23    JCV         2559         630         3189        Both   0.717613   \n",
      "24    NNJ         5135        1300         6435        Both   0.704711   \n",
      "25    QBE          134          49          183        Both   0.704545   \n",
      "26    NVB          672         155          827        Both   0.655914   \n",
      "27    NDT           59          15           74        Both   0.615385   \n",
      "28    QUE           73          17           90        Both   0.437500   \n",
      "29    NVF            0           1            1   Test Only   0.000000   \n",
      "30    VVF            0           1            1   Test Only   0.000000   \n",
      "31    ACV            2           0            2  Train Only   0.000000   \n",
      "32     NN            2           0            2  Train Only   0.000000   \n",
      "33    FRW            1           0            1  Train Only   0.000000   \n",
      "34    FSS            1           0            1  Train Only   0.000000   \n",
      "35   NNNP            1           0            1  Train Only   0.000000   \n",
      "36    NNp            1           0            1  Train Only   0.000000   \n",
      "37     UH            1           0            1  Train Only   0.000000   \n",
      "38    UNF            1           0            1  Train Only   0.000000   \n",
      "39    URL            1           0            1  Train Only   0.000000   \n",
      "40   VNF[            1           0            1  Train Only   0.000000   \n",
      "41    VNP            1           0            1  Train Only   0.000000   \n",
      "\n",
      "      Recall  F1-Score  \n",
      "0   0.999557  0.999778  \n",
      "1   0.997748  0.996625  \n",
      "2   0.972561  0.978528  \n",
      "3   0.950460  0.965492  \n",
      "4   0.971925  0.973226  \n",
      "5   0.980851  0.975661  \n",
      "6   0.981691  0.975314  \n",
      "7   0.980769  0.970341  \n",
      "8   0.957111  0.958192  \n",
      "9   0.949659  0.952096  \n",
      "10  0.930233  0.941176  \n",
      "11  0.967086  0.955067  \n",
      "12  0.955854  0.949217  \n",
      "13  0.907503  0.921916  \n",
      "14  0.945901  0.939256  \n",
      "15  0.939447  0.933738  \n",
      "16  0.945205  0.936299  \n",
      "17  0.934127  0.925496  \n",
      "18  0.904762  0.906667  \n",
      "19  0.866017  0.879406  \n",
      "20  0.840088  0.860710  \n",
      "21  0.843866  0.843866  \n",
      "22  0.853530  0.826953  \n",
      "23  0.782540  0.748671  \n",
      "24  0.816923  0.756680  \n",
      "25  0.632653  0.666667  \n",
      "26  0.787097  0.715543  \n",
      "27  0.533333  0.571429  \n",
      "28  0.411765  0.424242  \n",
      "29  0.000000  0.000000  \n",
      "30  0.000000  0.000000  \n",
      "31  0.000000  0.000000  \n",
      "32  0.000000  0.000000  \n",
      "33  0.000000  0.000000  \n",
      "34  0.000000  0.000000  \n",
      "35  0.000000  0.000000  \n",
      "36  0.000000  0.000000  \n",
      "37  0.000000  0.000000  \n",
      "38  0.000000  0.000000  \n",
      "39  0.000000  0.000000  \n",
      "40  0.000000  0.000000  \n",
      "41  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Step 1: Extract tags from datasets ---\n",
    "train_tags = [id2tag[tag_id] for sent in tokenized_dataset[\"train\"][\"labels\"] for tag_id in sent if tag_id != -100]\n",
    "test_tags = [id2tag[tag_id] for sent in tokenized_dataset[\"test\"][\"labels\"] for tag_id in sent if tag_id != -100]\n",
    "\n",
    "train_counter = Counter(train_tags)\n",
    "test_counter = Counter(test_tags)\n",
    "\n",
    "train_tag_set = set(train_counter.keys())\n",
    "test_tag_set = set(test_counter.keys())\n",
    "\n",
    "both_tags = sorted(train_tag_set & test_tag_set)\n",
    "train_only_tags = sorted(train_tag_set - test_tag_set)\n",
    "test_only_tags = sorted(test_tag_set - train_tag_set)\n",
    "\n",
    "# --- Step 2: Get classification report as dict ---\n",
    "# Ensure these lists are aligned with predictions\n",
    "report = classification_report(true_tags, predicted_tags, output_dict=True, zero_division=0)\n",
    "\n",
    "# --- Step 3: Combine all tags into rows ---\n",
    "rows = []\n",
    "\n",
    "# Helper function to pull metrics safely\n",
    "def get_metric(tag, metric):\n",
    "    return report[tag][metric] if tag in report else 0.0\n",
    "\n",
    "# Tags in both sets\n",
    "for tag in both_tags:\n",
    "    total = train_counter[tag] + test_counter[tag]\n",
    "    rows.append({\n",
    "        \"Tag\": tag,\n",
    "        \"Train Count\": train_counter[tag],\n",
    "        \"Test Count\": test_counter[tag],\n",
    "        \"Total Count\": total,\n",
    "        \"Tag Origin\": \"Both\",\n",
    "        \"Precision\": get_metric(tag, \"precision\"),\n",
    "        \"Recall\": get_metric(tag, \"recall\"),\n",
    "        \"F1-Score\": get_metric(tag, \"f1-score\")\n",
    "    })\n",
    "\n",
    "# Tags only in training\n",
    "for tag in train_only_tags:\n",
    "    rows.append({\n",
    "        \"Tag\": tag,\n",
    "        \"Train Count\": train_counter[tag],\n",
    "        \"Test Count\": 0,\n",
    "        \"Total Count\": train_counter[tag],\n",
    "        \"Tag Origin\": \"Train Only\",\n",
    "        \"Precision\": 0.0,\n",
    "        \"Recall\": 0.0,\n",
    "        \"F1-Score\": 0.0\n",
    "    })\n",
    "\n",
    "# Tags only in testing\n",
    "for tag in test_only_tags:\n",
    "    rows.append({\n",
    "        \"Tag\": tag,\n",
    "        \"Train Count\": 0,\n",
    "        \"Test Count\": test_counter[tag],\n",
    "        \"Total Count\": test_counter[tag],\n",
    "        \"Tag Origin\": \"Test Only\",\n",
    "        \"Precision\": get_metric(tag, \"precision\"),\n",
    "        \"Recall\": get_metric(tag, \"recall\"),\n",
    "        \"F1-Score\": get_metric(tag, \"f1-score\")\n",
    "    })\n",
    "\n",
    "# --- Step 4: Build DataFrame and sort within each category ---\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Sort within each group\n",
    "df = df.sort_values(by=[\"Tag Origin\", \"Precision\", \"Total Count\"], ascending=[True, False, False]).reset_index(drop=True)\n",
    "\n",
    "# --- Optional: Display or export ---\n",
    "pd.set_option(\"display.max_rows\", None)  # to see all rows\n",
    "print(df)\n",
    "\n",
    "# Optional export\n",
    "#df.to_csv(\"tag_analysis_num-of-ep-4.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad9b5c",
   "metadata": {},
   "source": [
    "### Save and Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d75c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sinhala-pos-xlm-r\\\\tokenizer_config.json',\n",
       " 'sinhala-pos-xlm-r\\\\special_tokens_map.json',\n",
       " 'sinhala-pos-xlm-r\\\\tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"sinhala-pos-xlm-r\")\n",
    "tokenizer.save_pretrained(\"sinhala-pos-xlm-r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e93add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'PRP', 'score': np.float32(0.9918686), 'word': '‡∂∏‡∂∏', 'start': 0, 'end': 2}], [{'entity_group': 'NNC', 'score': np.float32(0.828202), 'word': '‡∂¥‡∑è‡∑É‡∑ê‡∂Ω', 'start': 0, 'end': 5}], [{'entity_group': 'VFM', 'score': np.float32(0.8610128), 'word': '‡∂∫‡∂∏‡∑í', 'start': 0, 'end': 3}]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pos_pipeline = pipeline(\"token-classification\", model=\"sinhala-pos-xlm-r\", tokenizer=\"sinhala-pos-xlm-r\", aggregation_strategy=\"simple\")\n",
    "\n",
    "sentence = \"‡∂∏‡∂∏ ‡∂¥‡∑è‡∑É‡∑ê‡∂Ω ‡∂∫‡∂∏‡∑í\"\n",
    "tokens = sentence.split()  # Assuming simple whitespace tokenization\n",
    "print(pos_pipeline(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35386bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "GPU name: NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
