{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e252e51b",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e089373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pos_data(path):\n",
    "    dataset = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                # End of a sentence\n",
    "                if tokens:\n",
    "                    dataset.append({\"tokens\": tokens, \"tags\": tags})\n",
    "                    tokens = []\n",
    "                    tags = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    word, tag = parts\n",
    "                    tokens.append(word)\n",
    "                    tags.append(tag)\n",
    "        # Catch the last sentence if no newline at EOF\n",
    "        if tokens:\n",
    "            dataset.append({\"tokens\": tokens, \"tags\": tags})\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a3331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tokens': ['‡∂ä‡∑Å‡∑ä‡∂ª‡∑è‡∂∫‡∂Ω‡∑ä', '‡∂∏‡∑í‡∑É‡∂∫‡∑í‡∂Ω', '‡∂¥‡∑ä‡∂ª‡∑Ñ‡∑è‡∂ª', '‡∑Ä‡∂Ω‡∑í‡∂±‡∑ä', '‡∂¥‡∂Ω‡∑É‡∑ä‡∂≠‡∑ì‡∂±‡∑î‡∑Ä‡∑ù', '4', '‡∂ö‡∑ä', '‡∂∏‡∑í‡∂∫', '‡∂∫‡∂≠‡∑í', '.'], 'tags': ['NNP', 'NNJ', 'NNC', 'CM', 'NNP', 'NUM', 'RP', 'RRPCV', 'VFM', 'FS']}, {'tokens': ['‡∂ú‡∑è‡∑É‡∑è', '‡∂≠‡∑ì‡∂ª‡∂∫‡∑ö‡∂Ø‡∑ì', '.'], 'tags': ['NNP', 'NNP', 'FS']}]\n"
     ]
    }
   ],
   "source": [
    "print(load_pos_data(\"sinhala_pos.txt\")[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307ac143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "# all_data = load_pos_data(\"sinhala_pos.txt\")\n",
    "# random.shuffle(all_data)\n",
    "\n",
    "# # Optional: 80% train, 20% test split\n",
    "# split_idx = int(0.8 * len(all_data))\n",
    "# train_data = all_data[:split_idx]\n",
    "# test_data = all_data[split_idx:]\n",
    "\n",
    "# dataset = DatasetDict({\n",
    "#     \"train\": Dataset.from_list(train_data),\n",
    "#     \"test\": Dataset.from_list(test_data),\n",
    "# })\n",
    "\n",
    "data = load_pos_data(\"sinhala_pos.txt\")\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75e430",
   "metadata": {},
   "source": [
    "### tag2id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58584ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set(tag for example in data for tag in example[\"tags\"])\n",
    "\n",
    "tag2id = {tag: i for i, tag in enumerate(sorted(unique_tags))}\n",
    "label_list = list(tag2id.keys())\n",
    "\n",
    "id2tag = {i: tag for tag, i in tag2id.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac2906",
   "metadata": {},
   "source": [
    "### Tokenize and Align Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263ae3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9040/9040 [00:07<00:00, 1172.91 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2261/2261 [00:01<00:00, 1363.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"tokens\"], \n",
    "        is_split_into_words=True, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\",      # Pad to max length of the model or your max_length param\n",
    "        max_length=256,            # or any max_length you want (optional)\n",
    "        return_tensors=None        # don't convert to tensors here; Trainer does it later\n",
    "    )\n",
    "    \n",
    "    word_ids = tokenized.word_ids()\n",
    "    labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            labels.append(tag2id[example[\"tags\"][word_idx]])\n",
    "        else:\n",
    "            # Label only the first sub-token\n",
    "            labels.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db6892",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629a9d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    num_labels=len(tag2id),\n",
    "    id2label=id2tag,\n",
    "    label2id=tag2id,\n",
    "    local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ccb24e",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9231ff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_15088\\3450742309.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [565/565 1:21:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705700</td>\n",
       "      <td>0.343603</td>\n",
       "      <td>0.905514</td>\n",
       "      <td>0.904922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=565, training_loss=0.6697956051446695, metrics={'train_runtime': 4894.5893, 'train_samples_per_second': 1.847, 'train_steps_per_second': 0.115, 'total_flos': 1181488456581120.0, 'train_loss': 0.6697956051446695, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "# from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     preds = np.argmax(p.predictions, axis=2)\n",
    "#     labels = p.label_ids\n",
    "\n",
    "#     true_preds = [\n",
    "#         [id2tag[p] for (p, l) in zip(pred_seq, label_seq) if l != -100]\n",
    "#         for pred_seq, label_seq in zip(preds, labels)\n",
    "#     ]\n",
    "#     true_labels = [\n",
    "#         [id2tag[l] for (p, l) in zip(pred_seq, label_seq) if l != -100]\n",
    "#         for pred_seq, label_seq in zip(preds, labels)\n",
    "#     ]\n",
    "\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "#         \"report\": classification_report(true_labels, true_preds),\n",
    "#     }\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=2)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Convert IDs to tag names, skip padding (-100)\n",
    "\n",
    "    \n",
    "    true_preds = [\n",
    "        id2tag[p] for pred_seq, label_seq in zip(preds, labels)\n",
    "        for p, l in zip(pred_seq, label_seq) if l != -100\n",
    "    ]\n",
    "    true_labels = [\n",
    "        id2tag[l] for pred_seq, label_seq in zip(preds, labels)\n",
    "        for p, l in zip(pred_seq, label_seq) if l != -100\n",
    "    ]\n",
    "\n",
    "    # Optional: print detailed report to console (not return)\n",
    "    print(classification_report(true_labels, true_preds, digits=4))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds, average=\"weighted\"),\n",
    "        # Avoid printing report here in returned dict ‚Äî it's too long\n",
    "        # Use print manually if needed:\n",
    "        # print(classification_report(true_labels, true_preds))\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pos-xlm-r\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84beb556",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f613e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3436029255390167,\n",
       " 'eval_accuracy': 0.90551371868123,\n",
       " 'eval_f1': 0.9049217239183525,\n",
       " 'eval_runtime': 112.1416,\n",
       " 'eval_samples_per_second': 20.162,\n",
       " 'eval_steps_per_second': 1.266,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73480896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB       0.94      0.98      0.96       426\n",
      "         AUX       0.92      0.96      0.94       300\n",
      "          CC       0.97      0.96      0.96       687\n",
      "          CM       0.94      0.95      0.95       434\n",
      "         DET       0.96      0.96      0.96      1165\n",
      "         FRW       0.00      0.00      0.00         1\n",
      "          FS       1.00      1.00      1.00      2252\n",
      "         JCV       0.67      0.65      0.66       622\n",
      "          JJ       0.85      0.81      0.83      3557\n",
      "         NCV       0.72      0.80      0.76       927\n",
      "         NDT       0.00      0.00      0.00        14\n",
      "         NIP       0.97      0.96      0.97       857\n",
      "          NN       0.00      0.00      0.00         1\n",
      "         NNC       0.91      0.90      0.90     12213\n",
      "         NNJ       0.65      0.78      0.71      1296\n",
      "         NNP       0.93      0.92      0.93      5063\n",
      "         NNp       0.00      0.00      0.00         1\n",
      "         NUM       0.94      0.97      0.95      1166\n",
      "         NVB       0.59      0.61      0.60       174\n",
      "         NVF       0.00      0.00      0.00         1\n",
      "        POST       0.93      0.95      0.94      3628\n",
      "         PRP       0.97      0.94      0.96      1376\n",
      "        PUNC       0.99      1.00      1.00      1838\n",
      "         QBE       0.50      0.08      0.14        37\n",
      "         QUE       0.00      0.00      0.00        17\n",
      "          RB       0.78      0.77      0.77       496\n",
      "          RP       0.94      0.96      0.95      1275\n",
      "       RRPCV       0.83      0.86      0.85       844\n",
      "         UNK       0.00      0.00      0.00        55\n",
      "         URL       0.00      0.00      0.00         1\n",
      "         VFM       0.91      0.96      0.93      1346\n",
      "         VNF       0.92      0.91      0.91      2545\n",
      "         VNN       0.92      0.88      0.90      1417\n",
      "          VP       0.91      0.92      0.92      3498\n",
      "         VVF       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.91     49531\n",
      "   macro avg       0.64      0.64      0.64     49531\n",
      "weighted avg       0.91      0.91      0.90     49531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "preds = predictions_output.predictions.argmax(-1)\n",
    "labels = predictions_output.label_ids\n",
    "\n",
    "# Flatten predictions, ignoring -100\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for pred_seq, label_seq in zip(preds, labels):\n",
    "    for pred, label in zip(pred_seq, label_seq):\n",
    "        if label != -100:\n",
    "            true_labels.append(label)\n",
    "            predicted_labels.append(pred)\n",
    "\n",
    "# Dynamically detect used label IDs\n",
    "used_label_ids = sorted(set(true_labels + predicted_labels))\n",
    "\n",
    "# Match label IDs to tag names\n",
    "target_names = [id2tag[i] for i in used_label_ids]\n",
    "\n",
    "# Evaluate safely with matching label set\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    predicted_labels,\n",
    "    labels=used_label_ids,\n",
    "    target_names=target_names,\n",
    "    zero_division=0  # prevents warnings for unseen labels\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f32102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n",
      "üîç Evaluation Metrics from trainer.evaluate():\n",
      "eval_loss: 0.3436\n",
      "eval_accuracy: 0.9055\n",
      "eval_f1: 0.9049\n",
      "eval_runtime: 112.0800\n",
      "eval_samples_per_second: 20.1730\n",
      "eval_steps_per_second: 1.2670\n",
      "epoch: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Acedemic\\Level 4\\research\\RobeRta-POS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB     0.9433    0.9765    0.9596       426\n",
      "         AUX     0.9228    0.9567    0.9394       300\n",
      "          CC     0.9705    0.9578    0.9641       687\n",
      "          CM     0.9429    0.9516    0.9472       434\n",
      "         DET     0.9556    0.9597    0.9576      1165\n",
      "         FRW     0.0000    0.0000    0.0000         1\n",
      "          FS     0.9991    1.0000    0.9996      2252\n",
      "         JCV     0.6689    0.6527    0.6607       622\n",
      "          JJ     0.8517    0.8139    0.8324      3557\n",
      "         NCV     0.7161    0.8026    0.7569       927\n",
      "         NDT     0.0000    0.0000    0.0000        14\n",
      "         NIP     0.9728    0.9603    0.9665       857\n",
      "          NN     0.0000    0.0000    0.0000         1\n",
      "         NNC     0.9120    0.8966    0.9042     12213\n",
      "         NNJ     0.6509    0.7770    0.7084      1296\n",
      "         NNP     0.9302    0.9212    0.9257      5063\n",
      "         NNp     0.0000    0.0000    0.0000         1\n",
      "         NUM     0.9392    0.9666    0.9527      1166\n",
      "         NVB     0.5912    0.6149    0.6028       174\n",
      "         NVF     0.0000    0.0000    0.0000         1\n",
      "        POST     0.9270    0.9482    0.9375      3628\n",
      "         PRP     0.9745    0.9433    0.9586      1376\n",
      "        PUNC     0.9935    0.9978    0.9957      1838\n",
      "         QBE     0.5000    0.0811    0.1395        37\n",
      "         QUE     0.0000    0.0000    0.0000        17\n",
      "          RB     0.7758    0.7742    0.7750       496\n",
      "          RP     0.9379    0.9600    0.9488      1275\n",
      "       RRPCV     0.8331    0.8578    0.8453       844\n",
      "         UNK     0.0000    0.0000    0.0000        55\n",
      "         URL     0.0000    0.0000    0.0000         1\n",
      "         VFM     0.9063    0.9554    0.9302      1346\n",
      "         VNF     0.9181    0.9112    0.9146      2545\n",
      "         VNN     0.9200    0.8843    0.9018      1417\n",
      "          VP     0.9124    0.9202    0.9163      3498\n",
      "         VVF     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9055     49531\n",
      "   macro avg     0.6447    0.6412    0.6383     49531\n",
      "weighted avg     0.9052    0.9055    0.9049     49531\n",
      "\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ABB       0.94      0.98      0.96       426\n",
      "         AUX       0.92      0.96      0.94       300\n",
      "          CC       0.97      0.96      0.96       687\n",
      "          CM       0.94      0.95      0.95       434\n",
      "         DET       0.96      0.96      0.96      1165\n",
      "         FRW       0.00      0.00      0.00         1\n",
      "          FS       1.00      1.00      1.00      2252\n",
      "         JCV       0.67      0.65      0.66       622\n",
      "          JJ       0.85      0.81      0.83      3557\n",
      "         NCV       0.72      0.80      0.76       927\n",
      "         NDT       0.00      0.00      0.00        14\n",
      "         NIP       0.97      0.96      0.97       857\n",
      "          NN       0.00      0.00      0.00         1\n",
      "         NNC       0.91      0.90      0.90     12213\n",
      "         NNJ       0.65      0.78      0.71      1296\n",
      "         NNP       0.93      0.92      0.93      5063\n",
      "         NNp       0.00      0.00      0.00         1\n",
      "         NUM       0.94      0.97      0.95      1166\n",
      "         NVB       0.59      0.61      0.60       174\n",
      "         NVF       0.00      0.00      0.00         1\n",
      "        POST       0.93      0.95      0.94      3628\n",
      "         PRP       0.97      0.94      0.96      1376\n",
      "        PUNC       0.99      1.00      1.00      1838\n",
      "         QBE       0.50      0.08      0.14        37\n",
      "         QUE       0.00      0.00      0.00        17\n",
      "          RB       0.78      0.77      0.77       496\n",
      "          RP       0.94      0.96      0.95      1275\n",
      "       RRPCV       0.83      0.86      0.85       844\n",
      "         UNK       0.00      0.00      0.00        55\n",
      "         URL       0.00      0.00      0.00         1\n",
      "         VFM       0.91      0.96      0.93      1346\n",
      "         VNF       0.92      0.91      0.91      2545\n",
      "         VNN       0.92      0.88      0.90      1417\n",
      "          VP       0.91      0.92      0.92      3498\n",
      "         VVF       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.91     49531\n",
      "   macro avg       0.64      0.64      0.64     49531\n",
      "weighted avg       0.91      0.91      0.90     49531\n",
      "\n",
      "\n",
      "üìâ Confusion Matrix (label indices):\n",
      "[[ 416    0    0 ...    0    0    0]\n",
      " [   0  287    0 ...    0    3    0]\n",
      " [   0    0  658 ...    0    2    0]\n",
      " ...\n",
      " [   0    0    1 ... 1253   44    0]\n",
      " [   0    2    1 ...   22 3219    0]\n",
      " [   0    0    0 ...    1    0    0]]\n",
      "\n",
      "üîé Total mismatches found: 1718\n",
      "\n",
      "MISMATCHED SENTENCE 0\n",
      "True Tags : ['POST', 'NNC', 'CM', 'JJ', 'NCV', 'VNF', 'VP', 'RP', 'PRP', 'CM', 'NNC', 'DET', 'DET', 'NNC', 'VP', 'VP', 'JJ', 'JJ', 'JJ', 'NNC', 'VNN', 'VFM', 'FS']\n",
      "Pred Tags : ['POST', 'NNC', 'CM', 'NNC', 'NCV', 'VNF', 'VNF', 'RP', 'PRP', 'CM', 'NNC', 'DET', 'DET', 'NNC', 'VNF', 'VP', 'JJ', 'JJ', 'NNP', 'NNC', 'VNN', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 1\n",
      "True Tags : ['PRP', 'NNC', 'NNP', 'NNC', 'NNC', 'RRPCV', 'VP', 'POST', 'NCV', 'VP', 'JJ', 'NNJ', 'NNC', 'NNC', 'NNP', 'JJ', 'NNC', 'JJ', 'VFM', 'FS']\n",
      "Pred Tags : ['PRP', 'NNC', 'NNP', 'NNC', 'NNC', 'RRPCV', 'VP', 'POST', 'NCV', 'VP', 'JJ', 'NNJ', 'NNC', 'NNC', 'NNP', 'JJ', 'NNC', 'RRPCV', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 2\n",
      "True Tags : ['NDT', 'PRP', 'RRPCV', 'VFM', 'FS']\n",
      "Pred Tags : ['DET', 'NNC', 'RRPCV', 'VFM', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 3\n",
      "True Tags : ['DET', 'NNC', 'NCV', 'VP', 'DET', 'NNC', 'VP', 'JJ', 'NNC', 'VP', 'JJ', 'NNJ', 'NNC', 'NNC', 'NNC', 'NIP', 'NNC', 'CM', 'NNC', 'FS']\n",
      "Pred Tags : ['DET', 'NNC', 'NCV', 'VP', 'DET', 'NNC', 'VP', 'JJ', 'NNC', 'VP', 'JJ', 'JJ', 'NNC', 'NUM', 'NNC', 'NIP', 'NNC', 'CM', 'NVB', 'FS']\n",
      "\n",
      "MISMATCHED SENTENCE 4\n",
      "True Tags : ['NNP', 'NNP', 'NNC', 'VP', 'NNC', 'JJ', 'NNC', 'RRPCV', 'VNF', 'VNN', 'NNC', 'JJ', 'NNC', 'NNP', 'PUNC', 'NNP', 'NNC', 'VFM', 'FS']\n",
      "Pred Tags : ['NNP', 'NNP', 'NNC', 'VP', 'NNC', 'JJ', 'NNC', 'RRPCV', 'VNF', 'VNN', 'NNC', 'POST', 'NNC', 'NNP', 'PUNC', 'NNP', 'NNC', 'VFM', 'FS']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Evaluate overall metrics using Hugging Face Trainer\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"üîç Evaluation Metrics from trainer.evaluate():\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Step 2: Run predictions\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "predictions = predictions_output.predictions\n",
    "label_ids = predictions_output.label_ids\n",
    "\n",
    "# Step 3: Get most likely tag indices\n",
    "pred_labels = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Step 4: Prepare true and predicted tag names (flattened)\n",
    "true_tags = []\n",
    "predicted_tags = []\n",
    "\n",
    "# Optional: Track mismatches with sentence-level tags\n",
    "mismatches = []\n",
    "\n",
    "for i in range(len(label_ids)):\n",
    "    true_sent = []\n",
    "    pred_sent = []\n",
    "    for true_id, pred_id in zip(label_ids[i], pred_labels[i]):\n",
    "        if true_id != -100:\n",
    "            true_tag = id2tag[true_id]\n",
    "            pred_tag = id2tag[pred_id]\n",
    "            true_tags.append(true_tag)\n",
    "            predicted_tags.append(pred_tag)\n",
    "            true_sent.append(true_tag)\n",
    "            pred_sent.append(pred_tag)\n",
    "    \n",
    "    if true_sent != pred_sent:\n",
    "        mismatches.append((i, true_sent, pred_sent))\n",
    "\n",
    "# Step 5: Classification report\n",
    "unique_tags = sorted(list(set(true_tags + predicted_tags)))\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(true_tags, predicted_tags, labels=unique_tags, zero_division=0))\n",
    "\n",
    "# Step 6: Confusion matrix\n",
    "print(\"\\nüìâ Confusion Matrix (label indices):\")\n",
    "tag2id_filtered = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
    "y_true_ids = [tag2id_filtered[tag] for tag in true_tags]\n",
    "y_pred_ids = [tag2id_filtered[tag] for tag in predicted_tags]\n",
    "cm = confusion_matrix(y_true_ids, y_pred_ids)\n",
    "print(cm)\n",
    "\n",
    "# Step 7: Show a few mismatched sentences\n",
    "print(f\"\\nüîé Total mismatches found: {len(mismatches)}\")\n",
    "for idx, true_sent, pred_sent in mismatches[:5]:  # Limit to 5 for readability\n",
    "    print(f\"\\nMISMATCHED SENTENCE {idx + 1}\")\n",
    "    print(\"True Tags :\", true_sent)\n",
    "    print(\"Pred Tags :\", pred_sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad9b5c",
   "metadata": {},
   "source": [
    "### Save and Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d75c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"sinhala-pos-xlm-r\")\n",
    "tokenizer.save_pretrained(\"sinhala-pos-xlm-r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pos_pipeline = pipeline(\"token-classification\", model=\"sinhala-pos-xlm-r\", tokenizer=\"sinhala-pos-xlm-r\", aggregation_strategy=\"simple\")\n",
    "\n",
    "sentence = \"‡∂∏‡∂∏ ‡∂¥‡∑è‡∑É‡∑ê‡∂Ω ‡∂∫‡∂∏‡∑í\"\n",
    "tokens = sentence.split()  # Assuming simple whitespace tokenization\n",
    "print(pos_pipeline(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35386bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "GPU name: NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
